{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Recommendation Engines\n",
    "\n",
    "(This is for the Applied Data Science Group November/December 2017 session.)\n",
    "\n",
    "This notebook tries to build a recommendation engine, which an e-commerce sites would use to recommend other items to you.  Matt Borthwick scraped the data from user reviews at boardgamegeek.com.  This is an initial runthrough to check the quality of the data, and try to play with the distributions.  I'll try to check that the dataset seems sane, check the shape of the distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Possible questions:\n",
    "\n",
    "I did a similar brainstorming exercise (without looking at the data) to what we did in the first week:\n",
    "\n",
    "### Exploratory questions\n",
    "\n",
    "- What is the most popular game?\n",
    "  - Which has the highest average rating?\n",
    "  -  Which has the most reviews?\n",
    "  -  Same for lowest, least reviews\n",
    "\n",
    " - What is the most divisive game?\n",
    "  (Greatest spread in review scores)\n",
    "\n",
    "- Data quality: NA, None, NAN\n",
    "   Number of reviews per user?\n",
    "   Number of reviews per game?\n",
    "   Check scale of review scores\n",
    " - Check distributions of scores\n",
    "\n",
    "\n",
    "## Analysis/Modelling questions\n",
    "\n",
    "- Recommend new games based on similarities with others interests.\n",
    "\n",
    "   Build clustering algorithm based on scores in games.\n",
    "   - Assign each user a vector in Ngame-dim space.\n",
    "   - Find users with similar vectors, based on dot-product.  (K-means or some other clustering)?\n",
    "   - Remove games that are already reviewed, or with negative scores.\n",
    "   - Recommend remaining game with highest score.\n",
    "\n",
    "- User analysis:\n",
    "   Are there multiple audiences here? \"Hardcore\" vs \"casual\" to use the gamer terms.\n",
    "   - How many 1-review users are there? What games do they try out?\n",
    "   - What games do users with multiple reviews enjoy? \n",
    "\n",
    "- Scoring: How will we score/test our recommendations?  \n",
    "    - Some sort of cross-validation where we keep a game's scores back, \n",
    "    and try to predict how reviewers will score it, based on their other reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#standard library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#makes larger plots\n",
    "plt.rcParams['figure.figsize']=(10,6)\n",
    "\n",
    "#save graphics as pdf too (for less revolting exported plots)\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('png', 'pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#read in the data.  (13MB or so)\n",
    "#(N.B. I put Matt's header on it's own line, which is skipped, and added the UserID)\n",
    "#df=pd.read_csv('data/boardgame-ratings.csv',skiprows=1)\n",
    "df=pd.read_csv('data/boardgame-users.csv',skiprows=1)\n",
    "df.columns=('userID','gameID','rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   boardgamegeek.com game ID                    title\n0                      13004  The Downfall of Pompeii\n1                      66188                   Fresco\n2                        503       Through the Desert\n3                      66690     Dominion: Prosperity\n4                        150                 PitchCar"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_df=pd.read_csv('data/boardgame-titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   gameID                    title\n0   13004  The Downfall of Pompeii\n1   66188                   Fresco\n2     503       Through the Desert\n3   66690     Dominion: Prosperity\n4     150                 PitchCar"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_df.columns=('gameID','title')\n",
    "name_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "?pd.read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Exploratory Analysis\n",
    "\n",
    "I'm going to do a few things:\n",
    "- check for NaN/missing values.\n",
    "- check the scores look right\n",
    "- check the numbers of reviews, and games.\n",
    "- match up the names with the unique gameIDs (I'll find some missing entries here)\n",
    "- plot the number of reviews/user and reviews/game.\n",
    "- check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN 0\n",
      "Max/min scores 1.4013e-45 10.0\n"
     ]
    }
   ],
   "source": [
    "#test for NaN\n",
    "nan_array=np.isnan(df.values)\n",
    "print('Number of NaN',np.sum(nan_array))\n",
    "#check scale of review scores.\n",
    "print('Max/min scores',df['rating'].min(),df['rating'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#How many users, how many games?\n",
    "#Find the unique entries in each list\n",
    "users=df['userID'].unique()\n",
    "games=df['gameID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users is: 193504\n",
      "Number of unique games is: 402\n",
      "Total number of reviews is: 5148624\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique users is:',len(users))\n",
    "print('Number of unique games is:',len(games))\n",
    "print('Total number of reviews is:',len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "duplicated() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3d0985fb4807>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_dup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of duplicates: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: duplicated() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "#check for duplicates\n",
    "dup=df.duplicated()\n",
    "df_dup=df[dup]\n",
    "print('Number of duplicates: ',np.sum(dup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 14996 Ticket to Ride: Europe\n",
      "1 68448 7 Wonders\n",
      "2 13 Catan\n",
      "3 31260 Agricola\n",
      "4 178900 Codenames\n",
      "5 9209 Ticket to Ride\n",
      "6 30549 Pandemic\n",
      "7 129622 Love Letter\n",
      "8 36218 Dominion\n",
      "9 3076 Puerto Rico\n",
      "10 2651 Power Grid\n",
      "11 110327 Lords of Waterdeep\n",
      "12 822 Carcassonne\n",
      "13 478 Citadels\n",
      "14 39856 Dixit\n",
      "15 103 Titan\n",
      "16 148228 Splendor\n",
      "17 40692 Small World\n",
      "18 11 Bohnanza\n",
      "19 28143 Race for the Galaxy\n",
      "20 34635 Stone Age\n",
      "21 1927 Munchkin\n",
      "22 15987 Arkham Horror\n",
      "23 70323 King of Tokyo\n",
      "24 33154 Wasabi\n",
      "25 2163 Space Hulk\n",
      "26 197376 Charterstone\n"
     ]
    }
   ],
   "source": [
    "#make a dict to convert game labels to names (provided by Matt)\n",
    "#  Looks like we are missing the keys for 33154, 197376.  \n",
    "#I made up some keys for plotting/naming purposes.\n",
    "name_dict={11:\"Bohnanza\",\n",
    "68448:\"7 Wonders\",\n",
    "39856:\"Dixit\",\n",
    "40692:\"Small World\",\n",
    "31260:\"Agricola\",\n",
    "148228:\"Splendor\",\n",
    "13:\"Catan\",\n",
    "178900:\"Codenames\",\n",
    "34635:\"Stone Age\",\n",
    "28143:\"Race for the Galaxy\",\n",
    "129622:\"Love Letter\",\n",
    "14996:\"Ticket to Ride: Europe\",\n",
    "3076:\"Puerto Rico\",\n",
    "30549:\"Pandemic\",\n",
    "65244:\"Forbidden Island\",\n",
    "478:\"Citadels\",\n",
    "15987:\"Arkham Horror\",\n",
    "110327:\"Lords of Waterdeep\",\n",
    "36218:\"Dominion\",\n",
    "2651:\"Power Grid\",\n",
    "9209:\"Ticket to Ride\",\n",
    "103:\"Titan\",\n",
    "822:\"Carcassonne\",\n",
    "2163:\"Space Hulk\",\n",
    "1927:\"Munchkin\",\n",
    "70323:\"King of Tokyo\",\n",
    "33154:\"Wasabi\",\n",
    "197376:\"Charterstone\"}\n",
    "\n",
    "#check name dictionary is working.\n",
    "#I put in fake names earlier to find the missings ones\n",
    "i=0\n",
    "for num in games:\n",
    "    print(i,num,name_dict[num])\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3699 91\n"
     ]
    }
   ],
   "source": [
    "#Number of games with missing names\n",
    "msk1=df['gameID']==33154\n",
    "msk2=df['gameID']==197376\n",
    "print(np.sum(msk1),np.sum(msk2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Number of reviews/user and reviews/game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.395331544405289\n"
     ]
    }
   ],
   "source": [
    "avg_num_reviews=len(df)/len(users)\n",
    "print(avg_num_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So on average, each user reviews 5 games.  Let's try to build a histogram of users with a given number of reviews.  (and then the same with games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "##others mentioned issues with looping. let's also try a straightforward approach.\n",
    "##the following commented out code took a minute or two - untenable for only 1000 users!\n",
    "##make em\n",
    "#df_user=pd.DataFrame(columns=['Ngames'],index=users)\n",
    "# for user in users[0:4]:\n",
    "#     print(user)\n",
    "#     print('Ngames=',np.sum(df['userID']==user))\n",
    "\n",
    "#However, this version took a few seconds.\n",
    "user_review_counts=df.groupby(['userID']).count()\n",
    "#note that there really are users with ids going from 1 to 1000, its not a screwup.\n",
    "\n",
    "#On reflection, reshaping would be super helpful on this data set.  \n",
    "#Use 27 columns with one for each game, with a column for each score.      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f795f62d4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.figure(figsize=(12,9))\n",
    "plt.figure()\n",
    "plt.hist(user_review_counts.iloc[:,0].values,bins=np.arange(1,27))\n",
    "plt.xlabel('Number of Reviews')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.title('Reviewer distribution: Number of reviews per user')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Lots of single game reviewers, and then a long tail.  Relatively few people with more than 20 reviews. Lots of scope to recommend new gamesto people.  Might have to trim out the 1-game reviews when building the engine?\n",
    "Also a spike at 8 and 14 games?  Those might be interesting to look at too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#find the counts of reviews for each game.\n",
    "game_review_counts=df.groupby(['gameID']).count()\n",
    "#make a list matching up gameIDs and names.  Use that list as a new index\n",
    "new_index=[]\n",
    "for ind in game_review_counts.index:\n",
    "    new_index.append(name_dict[ind])\n",
    "\n",
    "game_review_counts.index=new_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f795cef9588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "game_review_counts.iloc[:,1].plot('bar')\n",
    "plt.ylabel('Number of reviews')\n",
    "plt.title('Number of reviews per game')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So, only a few games with less than 10000 reviews.  Charterstone (What I've previously called \"NOTAGAME2: NOT HARDER\"), only has 91 reviews, far fewer than everything else.\n",
    "From the point of view of the exercise, it's probably worth keeping that game, to let people consider the value in keeping that data point.\n",
    "Otherwise, this looks fairly balanced, and includes a few games with relatively few reviews, even 91 seems like a lot to be honest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Lets also try to look at the distributions of scores.  I'll try to make a box-plot.\n",
    "That will let me check the distributions in an easy manner.\n",
    "I'll pivot the data frame to make rows users, columns be games, with the entries given by the score. \n",
    "\n",
    "## Boxplots and Transforming the data\n",
    "\n",
    "Rearranging the data to use the gameIDs as columns would make sense for recommendation.\n",
    "For this data set, with 27 dim that's should be no problem. (Another question on what is best to do with thousands of entries).\n",
    "This would also make it easier to look at histograms on a per-game basis.\n",
    "I'm nigh certain pandas has a reshape function to do exactly this.  Pivot maybe?\n",
    "(http://pandas.pydata.org/pandas-docs/stable/reshaping.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#make a small dataframe for debugging purposes\n",
    "#df_small=df.iloc[0:1000]\n",
    "df_pivot=df.pivot(index='userID',columns='gameID',values='rating')\n",
    "df_pivot=df_pivot.rename(columns=name_dict)\n",
    "#df_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#df_pivot.to_csv('data/boardgame-ratings-pivot.csv')\n",
    "#?df.boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f795d609b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "game_review_counts=df_pivot.boxplot(rot=90,grid=False)\n",
    "plt.title('Score distributions by title')\n",
    "plt.ylabel('Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "These mostly look positive.  Not any radically skewed distributions, like all 1 or all 10.  Of the games I've played (Pandemic, Catan), the high ratings seem about plausible.  The overall ratings skew high, as one might expect for popular games.  There's a smattering of 10s from fanatics, and 1s from people who hated the games.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "(I'll imitate a plot I saw the more experienced folk do at the first finance-data meetup)\n",
    "Try a correlation map based on columns to see how close the score distributions are.\n",
    "I think this intuitively corresponds to: How much are the score distributions in one game similar to another?\n",
    "Running across the rows would yield something analogous for users (but would take an age, since that is a 1E5 x 1E5 matrix).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7956552668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_mat=df_pivot.corr()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(corr_mat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Barfs out a huge matrix of the actual numbers\n",
    "#print(c)\n",
    "?df_pivot.corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So what does that tell us?  Very Little?  The one game with an obvious signal (and negative correlations), \n",
    "is the one with 91 reviews.\n",
    "The games with high correlations are \"Ticket to ride\" and \"Ticket to ride: Europe\", which might be sequels, or expansions?  Otherwise, the other correlations all hover around the 0.1-0.3 range.\n",
    "\n",
    "As for building a dataset for recommendations engines, the low correlation is worrisome?  A high correlation implies that everyone likes the same games, in which case there is no space for a skillful recommendation.\n",
    "\n",
    "The low correlation might also be an artifact of lots of reviewers with only a single review. Those entries will have little correlation with anyone else, and may artificially lower the scores?  I also tried keeping only reviews with more than a few scores - it did nothing to change the overall picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#def reduced_corr(df)\n",
    "Nrow,Ncol=df_pivot.shape\n",
    "\n",
    "rcorr = np.zeros((Ncol,Ncol))\n",
    "Ncorr = np.zeros((Ncol,Ncol))\n",
    "Nreviews = np.zeros(Ncol)\n",
    "mu  = df_pivot.mean(axis=0)\n",
    "std = df_pivot.std(axis=0)\n",
    "\n",
    "#compute scaled dataframe\n",
    "scaled = ((df_pivot-mu)/std).values\n",
    "#scaled = ((df_pivot-5.5)/10).values\n",
    "\n",
    "Nmax=Ncol\n",
    "#compute correlations between entries, only where both games have been rated.\n",
    "for i in range(Nmax):\n",
    "    mski = ~np.isnan(scaled[:,i])\n",
    "    for j in range(i,Nmax):\n",
    "        mskj = ~np.isnan(scaled[:,j])\n",
    "        msk_tot = mski & mskj\n",
    "        x = scaled[msk_tot,i]\n",
    "        y = scaled[msk_tot,j]\n",
    "        Ncommon=np.sum(msk_tot)\n",
    "        c= np.dot(x,y)/(Ncommon-1)\n",
    "        rcorr[i,j]=c\n",
    "        rcorr[j,i]=c\n",
    "        Ncorr[i,j]=Ncommon\n",
    "\n",
    "# #check that the correlation is measuring something like the dot-product between the distributions.\n",
    "# x0=df_pivot.iloc[:,0].values\n",
    "# x1=df_pivot.iloc[:,1].values\n",
    "\n",
    "# x0_mu=np.nanmean(x0)\n",
    "# x1_mu=np.nanmean(x1)\n",
    "\n",
    "Ncorr=0.5*(Ncorr+Ncorr.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#find number of reviews within each integer bin size\n",
    "def game_hist(df):\n",
    "    df_counts=pd.DataFrame()\n",
    "    for i in range(1,11):\n",
    "        Ntot=(df.round()==i).sum(axis=0).astype(int)\n",
    "        df_counts=df_counts.append(Ntot,ignore_index=True)\n",
    "    df_counts.index=np.arange(1,11)\n",
    "    df_counts=df_counts/np.sum(df_counts)\n",
    "    return df_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_counts=game_hist(df_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Is there much similarity in the score distributions?  Not really useful question to ask.\n",
    "But the histogram plot is useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7920454c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(df_counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f792041dfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(corr_mat)\n",
    "plt.colorbar()\n",
    "plt.title('Pandas Correlation')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(rcorr)\n",
    "plt.colorbar()\n",
    "plt.title('\"Corrected\" Correlation')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(Ncorr)\n",
    "plt.colorbar()\n",
    "plt.title('Fraction of Common Reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f795463f400>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f79547d92b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i=5\n",
    "j=10\n",
    "plt.scatter(df_pivot.iloc[:,i],df_pivot.iloc[:,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The average pair-wise correlations between user's opinions of a game are really low.\n",
    "Maybe a cluster analysis might yield something non-trivial?\n",
    "This says on average, it's hard to guess what a person will think (in terms of variations from the mean).\n",
    "\n",
    "Looking over the numbers, the correlations seem to be based on 1000 ratings in common for any pair of games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##make logical array for actual reviews.\n",
    "#ntot=np.sum(df_pivot>0,axis=1)\n",
    "##only keep those with more than 6 review.\n",
    "#keep_msk=ntot>20\n",
    "#df_pivot2=df_pivot[keep_msk]\n",
    "#len(df_pivot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Conclusions regarding state of data\n",
    "\n",
    "The only thing that I really think needs fixing are the missing names for: 33154, 197376.\n",
    "\n",
    "The data does suggest some interesting questions on its own on the population of boardgamers.\n",
    "I suspect there is plenty of information that can be extracted here.  \n",
    "There is also a matter of having some data cleaning/munging to do on the full data set.\n",
    "Nothing looks too weird in the data.\n",
    "\n",
    "- The number of reviews per user is skewed towards new folks (not unreasonable, given how few people can stick at something as time intensive as playing and reviewing board games).\n",
    "\n",
    "- Looking at the box-plots, the scores seem fairly high, which tallies with what Matt said about picking popular games.  There doesn't seem anything obviously wrong with the distributions (all zero, or all 10s).\n",
    "\n",
    "- I think for analysis, it would be beneficial to reshape the dataframe/array, but that is probably best left to the participants, as is removing any data with few reviews.  I used \"pivot\" to transform the gameID column, into a new set of columns, while keeping the reviewers as rows.  This will make building feature vectors straightforward.\n",
    "\n",
    "- I tried building up some histograms via looping, and it was indeed quite slow.  In contrast, the arcane, built-in functions (groupby) are super fast.  The smaller dataset should allow accessibility to new people, while the full dataset is quite manageable if you find the right set of functions.  I haven't done any actual machine-learning with this yet, so maybe I'll eat my words about \"manageable\".\n",
    "\n",
    "- The correlation plots seem to show a small, positive correlation.  Is this even a sensible measure?  Its something like the overlap between the shapes of the ratings distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Splitting into training/test\n",
    "\n",
    "I'm going to manually force a training/test split.  I'm going to randomly select 10% of users. \n",
    "Our goal is to recommend games people will like.  I'll try to test the predictions by holding back both some \"new\" users.\n",
    "I thought about keepng back some game data, but that's fairly sparse, and I'm not sure about the distribution (how representative any one game is).\n",
    "I think I'll try it anyway: select 2 games as holdouts.  I'm going to do that by hand (a game I've heard of, and a game that's new to me).\n",
    "\n",
    "Some questions:do we have enough data for this to make sense?  I am mostly concerned by the number of games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Ngames=len(games)\n",
    "Nusers=len(users)\n",
    "\n",
    "ngame_select=2\n",
    "nuser_select=int(len(users)/10)\n",
    "\n",
    "#make a list of uniform random numbers (times appropriate lengths)\n",
    "game_fixed=[12,14]  #I've at least heard of Agricola, (rules heavy \"Eurogame\")\n",
    "user_ix=np.random.random(size=Nusers)<0.1\n",
    "\n",
    "#keep testing examples from to test new users on old games, and new games on old users.\n",
    "df_user_test=df_pivot.iloc[user_ix,~game_ix]\n",
    "df_game_test=df_pivot.iloc[~user_ix,game_ix]\n",
    "\n",
    "#keep only the non-testing examples\n",
    "df_train = df_pivot.iloc[~user_ix,:]\n",
    "df_train = df_train.iloc[:,~game_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f79204ba208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_counts=game_hist(df_train)\n",
    "plt.imshow(df_counts/np.sum(df_counts))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "##Try some clustering to identify populations.\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#convert dataframe into \n",
    "df_mat=df_train.values\n",
    "nan_msk=np.isnan(df_mat)\n",
    "df_mat[nan_msk]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Try minibatch Kmeans (as recommended)\n",
    "Nclasses=4\n",
    "km=KMeans(n_clusters=Nclasses)\n",
    "km.fit(df_mat)\n",
    "ypred=km.predict(df_mat)\n",
    "df_train['Class']=ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f79203a14a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#now to try visualizing\n",
    "plt.figure(figsize=(15,6))\n",
    "for i in range(Nclasses):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    msk=df_train['Class']==i\n",
    "    d0=game_hist(df_train[msk])\n",
    "    plt.imshow(d0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23303188547375681"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns[7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f792039a048>"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f79208728d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train.iloc[:,7].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "So this naive initial clustering, is choosing based on the score to game 7, \"Power Grid\".  What's special about that game?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "name": "recommend.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
